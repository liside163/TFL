# -*- coding: utf-8 -*-
"""
==============================================================================
æ•°æ®è¯Šæ–­è„šæœ¬ - æ£€æµ‹ç±»åˆ«ä¸å¹³è¡¡å’Œåˆ†å¸ƒé—®é¢˜
==============================================================================
åŠŸèƒ½ï¼šè¯Šæ–­å•å·¥å†µæ•°æ®é›†çš„æ½œåœ¨é—®é¢˜
- ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
- ä¸å¹³è¡¡æ£€æµ‹
- é›¶æ ·æœ¬ç±»åˆ«æ£€æµ‹

ä½¿ç”¨æ–¹å¼ï¼š
---------
python diagnose_data.py --condition 0

ä½œè€…ï¼šUAV-DANNé¡¹ç›®
æ—¥æœŸï¼š2025å¹´
==============================================================================
"""

import os
import sys
import argparse
import numpy as np
import pandas as pd
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from data.preprocess_single_condition import load_single_condition_data


def diagnose_single_condition(condition: int, results_dir: str = None):
    """
    è¯Šæ–­å•å·¥å†µæ•°æ®é›†

    Args:
        condition: é£è¡ŒçŠ¶æ€ä»£ç  (0-5)
        results_dir: ç»“æœç›®å½•
    """
    print("=" * 70)
    print(f"æ•°æ®è¯Šæ–­æŠ¥å‘Š - å·¥å†µ {condition}")
    print("=" * 70)

    # åŠ è½½æ•°æ®
    if results_dir is None:
        results_dir = './results/single_condition'

    try:
        data_dict = load_single_condition_data(condition, results_dir)
        condition_name = data_dict.get('condition_name', f'Condition_{condition}')
        print(f"\nå·¥å†µåç§°: {condition_name}")
    except Exception as e:
        print(f"\nâŒ æ— æ³•åŠ è½½æ•°æ®: {e}")
        print(f"   è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®é¢„å¤„ç†: python data/preprocess_single_condition.py --condition {condition}")
        return

    # 1. ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
    print("\n" + "=" * 70)
    print("1. ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡")
    print("=" * 70)

    source_train_dist = np.bincount(data_dict['y_source_train'], minlength=7)
    source_val_dist = np.bincount(data_dict['y_source_val'], minlength=7)
    target_train_dist = np.bincount(data_dict['y_target_train'], minlength=7)
    target_test_dist = np.bincount(data_dict['y_target_test'], minlength=7)

    fault_names = ['No_Fault', 'Motor', 'Accelerometer', 'Gyroscope',
                   'Magnetometer', 'Barometer', 'GPS']

    print("\næºåŸŸ (HIL) è®­ç»ƒé›†:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(data_dict['y_source_train']):,}")
    print(f"  ç±»åˆ«åˆ†å¸ƒ:")
    for i, (count, name) in enumerate(zip(source_train_dist, fault_names)):
        pct = count / len(data_dict['y_source_train']) * 100 if len(data_dict['y_source_train']) > 0 else 0
        print(f"    ç±»åˆ«{i} ({name:12s}): {count:6d} ({pct:5.2f}%)")

    print("\næºåŸŸ (HIL) éªŒè¯é›†:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(data_dict['y_source_val']):,}")
    print(f"  ç±»åˆ«åˆ†å¸ƒ:")
    for i, (count, name) in enumerate(zip(source_val_dist, fault_names)):
        pct = count / len(data_dict['y_source_val']) * 100 if len(data_dict['y_source_val']) > 0 else 0
        print(f"    ç±»åˆ«{i} ({name:12s}): {count:6d} ({pct:5.2f}%)")

    print("\nç›®æ ‡åŸŸ (Real) æµ‹è¯•é›†:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(data_dict['y_target_test']):,}")
    print(f"  ç±»åˆ«åˆ†å¸ƒ:")
    for i, (count, name) in enumerate(zip(target_test_dist, fault_names)):
        pct = count / len(data_dict['y_target_test']) * 100 if len(data_dict['y_target_test']) > 0 else 0
        print(f"    ç±»åˆ«{i} ({name:12s}): {count:6d} ({pct:5.2f}%)")

    # 2. ç±»åˆ«ä¸å¹³è¡¡æ£€æµ‹
    print("\n" + "=" * 70)
    print("2. ç±»åˆ«ä¸å¹³è¡¡æ£€æµ‹")
    print("=" * 70)

    # æºåŸŸè®­ç»ƒé›†ä¸å¹³è¡¡åˆ†æ
    max_count = source_train_dist.max()
    min_count = source_train_dist[source_train_dist > 0].min() if source_train_dist[source_train_dist > 0].size > 0 else 0
    imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')

    print(f"\næºåŸŸè®­ç»ƒé›†ä¸å¹³è¡¡æ¯”: {imbalance_ratio:.1f}:1 (æœ€å¤šç±»/æœ€å°‘ç±»)")
    print(f"  æœ€å¤šç±»æ ·æœ¬æ•°: {max_count}")
    print(f"  æœ€å°‘ç±»æ ·æœ¬æ•°: {min_count}")

    if imbalance_ratio > 50:
        print("  âŒ ä¸¥é‡ä¸å¹³è¡¡ï¼å»ºè®®:")
        print("     - ä½¿ç”¨æ•°æ®å¢å¼º (oversampling)")
        print("     - è°ƒæ•´ç±»åˆ«æƒé‡")
        print("     - è€ƒè™‘åˆå¹¶ç¨€æœ‰ç±»åˆ«")
    elif imbalance_ratio > 10:
        print("  âš ï¸  ä¸­åº¦ä¸å¹³è¡¡ï¼Œå»ºè®®ä½¿ç”¨ç±»åˆ«åŠ æƒ")
    else:
        print("  âœ“ ç›¸å¯¹å¹³è¡¡")

    # 3. é›¶æ ·æœ¬ç±»åˆ«æ£€æµ‹
    print("\n" + "=" * 70)
    print("3. é›¶æ ·æœ¬ç±»åˆ«æ£€æµ‹")
    print("=" * 70)

    zero_classes_train = np.where(source_train_dist == 0)[0]
    zero_classes_val = np.where(source_val_dist == 0)[0]
    zero_classes_target = np.where(target_test_dist == 0)[0]

    if len(zero_classes_train) > 0:
        print(f"\nâŒ æºåŸŸè®­ç»ƒé›†ç¼ºå°‘ç±»åˆ«: {zero_classes_train}")
        for cls in zero_classes_train:
            print(f"   ç±»åˆ«{cls} ({fault_names[cls]}): è®­ç»ƒé›†ä¸­æ ·æœ¬æ•°ä¸º0ï¼Œæ¨¡å‹æ— æ³•å­¦ä¹ æ­¤æ•…éšœï¼")
    else:
        print("\nâœ“ æºåŸŸè®­ç»ƒé›†åŒ…å«æ‰€æœ‰ç±»åˆ«")

    if len(zero_classes_val) > 0:
        print(f"\nâš ï¸  æºåŸŸéªŒè¯é›†ç¼ºå°‘ç±»åˆ«: {zero_classes_val}")
    else:
        print("âœ“ æºåŸŸéªŒè¯é›†åŒ…å«æ‰€æœ‰ç±»åˆ«")

    if len(zero_classes_target) > 0:
        print(f"\nâš ï¸  ç›®æ ‡åŸŸæµ‹è¯•é›†ç¼ºå°‘ç±»åˆ«: {zero_classes_target}")
    else:
        print("âœ“ ç›®æ ‡åŸŸæµ‹è¯•é›†åŒ…å«æ‰€æœ‰ç±»åˆ«")

    # 4. åŸŸé—´åˆ†å¸ƒå¯¹æ¯”
    print("\n" + "=" * 70)
    print("4. åŸŸé—´åˆ†å¸ƒå¯¹æ¯” (æºåŸŸ vs ç›®æ ‡åŸŸ)")
    print("=" * 70)

    source_total = source_train_dist.sum() + source_val_dist.sum()
    target_total = target_train_dist.sum() + target_test_dist.sum()

    print(f"\næ€»æ ·æœ¬æ•°å¯¹æ¯”:")
    print(f"  æºåŸŸ (HIL):   {source_total:,}")
    print(f"  ç›®æ ‡åŸŸ (Real): {target_total:,}")
    print(f"  æº/ç›®æ ‡æ¯”: {source_total/target_total:.2f}" if target_total > 0 else "  æº/ç›®æ ‡æ¯”: N/A")

    print(f"\nå„ç±»åˆ«æº/ç›®æ ‡åŸŸæ ·æœ¬æ•°å¯¹æ¯”:")
    print(f"{'ç±»åˆ«':<8} {'æ•…éšœç±»å‹':<15} {'æºåŸŸ':<10} {'ç›®æ ‡åŸŸ':<10} {'æ¯”ä¾‹':<10}")
    print("-" * 60)
    for i in range(7):
        source_count = source_train_dist[i] + source_val_dist[i]
        target_count = target_train_dist[i] + target_test_dist[i]
        ratio = source_count / target_count if target_count > 0 else float('inf')
        print(f"{i:<8} {fault_names[i]:<15} {source_count:<10} {target_count:<10} {ratio:<10.2f}")

    # 5. æ¨èçš„ç±»åˆ«æƒé‡
    print("\n" + "=" * 70)
    print("5. æ¨èçš„ç±»åˆ«æƒé‡ (é€†é¢‘ç‡åŠ æƒ)")
    print("=" * 70)

    # è®¡ç®—é€†é¢‘ç‡æƒé‡
    class_counts = source_train_dist.astype(np.float32)
    class_counts = np.maximum(class_counts, 1.0)  # é¿å…é™¤é›¶
    weights = 1.0 / class_counts
    weights = weights / weights.sum() * 7  # å½’ä¸€åŒ–

    print(f"\nç±»åˆ«æƒé‡ (ç”¨äºCrossEntropyLoss):")
    for i, (w, name) in enumerate(zip(weights, fault_names)):
        print(f"  ç±»åˆ«{i} ({name:12s}): {w:.4f}")

    # 6. æ€»ç»“å’Œå»ºè®®
    print("\n" + "=" * 70)
    print("6. æ€»ç»“å’Œå»ºè®®")
    print("=" * 70)

    issues = []
    warnings = []

    # æ£€æŸ¥é—®é¢˜
    if imbalance_ratio > 50:
        issues.append(f"ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ (æ¯”ä¾‹{imbalance_ratio:.1f}:1)")

    if len(zero_classes_train) > 0:
        issues.append(f"è®­ç»ƒé›†ç¼ºå°‘{len(zero_classes_train)}ä¸ªç±»åˆ«")

    if source_total < 5000:
        warnings.append(f"æºåŸŸæ ·æœ¬æ•°è¾ƒå°‘ ({source_total})ï¼Œå¯èƒ½æ¬ æ‹Ÿåˆ")

    if imbalance_ratio > 10:
        warnings.append(f"ä¸­åº¦ç±»åˆ«ä¸å¹³è¡¡ï¼Œå»ºè®®ä½¿ç”¨ç±»åˆ«æƒé‡")

    # è¾“å‡ºæ€»ç»“
    if len(issues) == 0 and len(warnings) == 0:
        print("\nâœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ— æ˜æ˜¾é—®é¢˜")
    else:
        if len(issues) > 0:
            print("\nâŒ å‘ç°ä»¥ä¸‹é—®é¢˜:")
            for issue in issues:
                print(f"   - {issue}")

        if len(warnings) > 0:
            print("\nâš ï¸  æ³¨æ„äº‹é¡¹:")
            for warning in warnings:
                print(f"   - {warning}")

    # è®­ç»ƒå»ºè®®
    print("\nğŸ“‹ è®­ç»ƒå»ºè®®:")
    if imbalance_ratio > 10:
        print("   âœ“ ä½¿ç”¨ç±»åˆ«åŠ æƒæŸå¤±å‡½æ•° (å·²åœ¨é…ç½®ä¸­å¯ç”¨)")
        print("   âœ“ å»ºè®®batch_sizeè®¾ä¸º32-64ä»¥åŒ…å«æ›´å¤šç¨€æœ‰ç±»æ ·æœ¬")

    if imbalance_ratio > 50:
        print("   âœ“ è€ƒè™‘ä½¿ç”¨æ•°æ®å¢å¼º (SMOTE, ADASYNç­‰)")
        print("   âœ“ è€ƒè™‘å¯¹ç¨€æœ‰ç±»è¿›è¡Œoversampling")

    print("   âœ“ ä½¿ç”¨å·²ä¿®å¤çš„åŸŸé€‚åº”å‚æ•° (gamma_grl=2.0, warmup=30)")
    print("   âœ“ ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­æºåŸŸå’Œç›®æ ‡åŸŸçš„å‡†ç¡®ç‡å˜åŒ–")

    print("\n" + "=" * 70)
    print("è¯Šæ–­å®Œæˆï¼")
    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(description='UAV-DANN æ•°æ®è¯Šæ–­å·¥å…·')
    parser.add_argument('--condition', type=int, default=0,
                        help='é£è¡ŒçŠ¶æ€ä»£ç  (0-5): 0=hover, 1=waypoint, 2=velocity, '
                             '3=circling, 4=acce, 5=dece')
    parser.add_argument('--results_dir', type=str, default=None,
                        help='ç»“æœç›®å½• (é»˜è®¤: ./results/single_condition)')

    args = parser.parse_args()

    if args.condition not in range(6):
        print(f"[é”™è¯¯] é£è¡ŒçŠ¶æ€ä»£ç å¿…é¡»åœ¨0-5ä¹‹é—´")
        return

    diagnose_single_condition(args.condition, args.results_dir)


if __name__ == "__main__":
    main()
