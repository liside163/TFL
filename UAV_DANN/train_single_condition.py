# -*- coding: utf-8 -*-
"""
==============================================================================
å•å·¥å†µ DANN è®­ç»ƒè„šæœ¬
==============================================================================
åŠŸèƒ½ï¼šé’ˆå¯¹å•ä¸€é£è¡ŒçŠ¶æ€ï¼ˆå·¥å†µï¼‰è¿›è¡Œ HILâ†’REAL åŸŸé€‚åº”è®­ç»ƒ

å·¥å†µ (é£è¡ŒçŠ¶æ€) å…±6ç§:
  0=hover, 1=waypoint, 2=velocity, 3=circling, 4=acce, 5=dece

ä½¿ç”¨æ–¹å¼ï¼š
---------
# è®­ç»ƒ hover å·¥å†µ
python train_single_condition.py --condition 0

# è®­ç»ƒ waypoint å·¥å†µ
python train_single_condition.py --condition 1

ä½œè€…ï¼šUAV-DANNé¡¹ç›®
æ—¥æœŸï¼š2025å¹´
==============================================================================
"""

import os
import sys
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from typing import Dict, Optional
from tqdm import tqdm
import yaml
import json
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from data.preprocess_single_condition import SingleConditionPreprocessor, load_single_condition_data
from data.dataloader import UAVDataset, DANNDataLoader
from models.dann import build_dann_from_config
from utils.metrics import calculate_metrics
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


def plot_dual_confusion_matrix(source_labels, source_preds, target_labels, target_preds,
                                class_names, save_path, condition_name):
    """
    ç»˜åˆ¶æºåŸŸå’Œç›®æ ‡åŸŸçš„åŒæ··æ·†çŸ©é˜µ
    
    Args:
        source_labels: æºåŸŸçœŸå®æ ‡ç­¾
        source_preds: æºåŸŸé¢„æµ‹æ ‡ç­¾
        target_labels: ç›®æ ‡åŸŸçœŸå®æ ‡ç­¾
        target_preds: ç›®æ ‡åŸŸé¢„æµ‹æ ‡ç­¾
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        condition_name: å·¥å†µåç§°
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # æºåŸŸæ··æ·†çŸ©é˜µ
    cm_source = confusion_matrix(source_labels, source_preds)
    sns.heatmap(cm_source, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names,
                ax=ax1, cbar_kws={'label': 'Count'})
    ax1.set_title(f'Source Domain (HIL) - {condition_name}\nAccuracy: {(source_preds == source_labels).mean():.2%}', 
                  fontsize=14, fontweight='bold')
    ax1.set_xlabel('Predicted Label', fontsize=12)
    ax1.set_ylabel('True Label', fontsize=12)
    
    # ç›®æ ‡åŸŸæ··æ·†çŸ©é˜µ
    cm_target = confusion_matrix(target_labels, target_preds)
    sns.heatmap(cm_target, annot=True, fmt='d', cmap='Oranges',
                xticklabels=class_names, yticklabels=class_names,
                ax=ax2, cbar_kws={'label': 'Count'})
    ax2.set_title(f'Target Domain (Real) - {condition_name}\nAccuracy: {(target_preds == target_labels).mean():.2%}',
                  fontsize=14, fontweight='bold')
    ax2.set_xlabel('Predicted Label', fontsize=12)
    ax2.set_ylabel('True Label', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"[ä¿¡æ¯] åŒæ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")


class FocalLoss(nn.Module):
    """
    Focal Loss - è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
    
    è®ºæ–‡: "Focal Loss for Dense Object Detection" (Lin et al., 2017)
    
    å…¬å¼: FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)
    
    Args:
        gamma: èšç„¦å‚æ•°ï¼Œè¶Šå¤§è¶Šå…³æ³¨éš¾åˆ†ç±»æ ·æœ¬ (é»˜è®¤2.0)
        alpha: ç±»åˆ«æƒé‡å¼ é‡ï¼Œç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        reduction: 'mean' æˆ– 'sum'
    """
    def __init__(self, gamma: float = 2.0, alpha: torch.Tensor = None, reduction: str = 'mean'):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = reduction
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        Args:
            inputs: æ¨¡å‹è¾“å‡º logits, shape = (N, C)
            targets: çœŸå®æ ‡ç­¾, shape = (N,)
        Returns:
            focal loss å€¼
        """
        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)
        pt = torch.exp(-ce_loss)  # p_t = exp(-CE)
        focal_loss = ((1 - pt) ** self.gamma) * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        return focal_loss


def compute_class_weights(y: np.ndarray, num_classes: int, device: torch.device) -> torch.Tensor:
    """
    è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆå¹³æ–¹æ ¹é€†é¢‘ç‡åŠ æƒ - æ›´ä¿å®ˆï¼‰
    
    ä½¿ç”¨å¹³æ–¹æ ¹ç¼“è§£æç«¯æƒé‡ï¼š
    - åŸå§‹é€†é¢‘ç‡: weight = 1/count â†’ æç«¯ä¸å¹³è¡¡æ—¶å·®å¼‚å·¨å¤§ (å¦‚0.08 vs 1.36)
    - å¹³æ–¹æ ¹é€†é¢‘ç‡: weight = 1/sqrt(count) â†’ å·®å¼‚æ›´æ¸©å’Œ (å¦‚0.28 vs 1.16)
    
    Args:
        y: æ ‡ç­¾æ•°ç»„
        num_classes: ç±»åˆ«æ•°
        device: è®¾å¤‡
        
    Returns:
        æƒé‡å¼ é‡, shape = (num_classes,)
    """
    class_counts = np.bincount(y, minlength=num_classes).astype(np.float32)
    # é¿å…é™¤é›¶
    class_counts = np.maximum(class_counts, 1.0)
    
    # ========== æ–¹æ¡ˆ2ï¼šå¹³æ–¹æ ¹é€†é¢‘ç‡æƒé‡ï¼ˆæ›´ä¿å®ˆï¼‰==========
    # ä½¿ç”¨å¹³æ–¹æ ¹ç¼“è§£æç«¯æƒé‡ï¼Œé¿å…è¿‡åº¦æƒ©ç½š/å¥–åŠ±æŸäº›ç±»åˆ«
    weights = 1.0 / np.sqrt(class_counts)
    
    # å½’ä¸€åŒ–ä½¿æƒé‡å’Œä¸º num_classes
    weights = weights / weights.sum() * num_classes
    
    print(f"[ä¿¡æ¯] ç±»åˆ«åˆ†å¸ƒ: {class_counts.astype(int)}")
    print(f"[ä¿¡æ¯] å¹³æ–¹æ ¹æƒé‡: {np.round(weights, 3)} (åŸé€†é¢‘ç‡æƒé‡ä¼šå¯¼è‡´è¿‡åº¦ä¸å¹³è¡¡)")
    
    return torch.FloatTensor(weights).to(device)


class LabelSmoothingCrossEntropy(nn.Module):
    """
    Label Smoothing äº¤å‰ç†µæŸå¤±
    
    è®ºæ–‡: "Rethinking the Inception Architecture for Computer Vision" (Szegedy et al., 2016)
    
    åŸç†: å°†ç¡¬æ ‡ç­¾ [0, 0, 1, 0] è½¯åŒ–ä¸º [0.025, 0.025, 0.925, 0.025]
    ä¼˜åŠ¿: é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
    
    Args:
        num_classes: ç±»åˆ«æ•°
        epsilon: å¹³æ»‘ç³»æ•° (æ¨è 0.05-0.2)
        weight: ç±»åˆ«æƒé‡ï¼ˆå¯é€‰ï¼‰
    """
    def __init__(self, num_classes: int, epsilon: float = 0.1, weight: torch.Tensor = None):
        super(LabelSmoothingCrossEntropy, self).__init__()
        self.num_classes = num_classes
        self.epsilon = epsilon
        self.weight = weight
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        Args:
            inputs: logits, shape = (B, C)
            targets: labels, shape = (B,)
        Returns:
            loss: æ ‡é‡
        """
        log_probs = F.log_softmax(inputs, dim=-1)
        
        with torch.no_grad():
            # åˆ›å»ºå¹³æ»‘æ ‡ç­¾
            targets_one_hot = F.one_hot(targets, num_classes=self.num_classes).float()
            smooth_targets = (1 - self.epsilon) * targets_one_hot + self.epsilon / self.num_classes
        
        # å¦‚æœæœ‰ç±»åˆ«æƒé‡ï¼Œåº”ç”¨æƒé‡
        if self.weight is not None:
            per_sample_weight = self.weight[targets]
            loss = -(smooth_targets * log_probs).sum(dim=-1) * per_sample_weight
            return loss.mean()
        else:
            loss = -(smooth_targets * log_probs).sum(dim=-1)
            return loss.mean()


def set_seed(seed: int) -> None:
    """è®¾ç½®éšæœºç§å­"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True


def get_device(config: dict) -> torch.device:
    """è·å–è®¡ç®—è®¾å¤‡"""
    if config['device']['use_gpu'] and torch.cuda.is_available():
        device = torch.device(f"cuda:{config['device']['gpu_id']}")
        print(f"[ä¿¡æ¯] ä½¿ç”¨GPU: {torch.cuda.get_device_name(device)}")
    else:
        device = torch.device('cpu')
        print("[ä¿¡æ¯] ä½¿ç”¨CPU")
    return device


def get_dataloaders_single_condition(data_dict: Dict, config: dict, sc_config: dict) -> Dict:
    """ä¸ºå•å·¥å†µæ•°æ®åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰åŠ æƒé‡‡æ ·ï¼‰"""
    sc_training = sc_config.get('training', {})
    batch_size = sc_training.get('batch_size', config['training']['batch_size'])

    loss_config = sc_training.get('loss', {})
    loss_type = loss_config.get('classification', 'focal_loss')
    use_class_weights = loss_config.get('use_class_weights')
    if use_class_weights is None:
        use_class_weights = loss_type != 'focal_loss'

    dataloader_config = sc_training.get('dataloader', {})
    use_weighted_sampler = dataloader_config.get('use_weighted_sampler')
    if use_weighted_sampler is None:
        use_weighted_sampler = not (loss_type == 'focal_loss' and not use_class_weights)
    if use_weighted_sampler and use_class_weights:
        print("[è­¦å‘Š] åŠ æƒé‡‡æ · + ç±»åˆ«åŠ æƒæŸå¤±ä¼šåŒé‡æƒ©ç½šå¤§ç±»æ ·æœ¬ï¼Œå»ºè®®åªå¯ç”¨ä¸€ç§ã€‚")
    
    source_train_dataset = UAVDataset(data_dict['X_source_train'], data_dict['y_source_train'], domain_label=0)
    source_val_dataset = UAVDataset(data_dict['X_source_val'], data_dict['y_source_val'], domain_label=0)
    target_train_dataset = UAVDataset(data_dict['X_target_train'], data_dict['y_target_train'], domain_label=1)
    target_test_dataset = UAVDataset(data_dict['X_target_test'], data_dict['y_target_test'], domain_label=1)
    
    # ========== å¯é€‰åŠ æƒé‡‡æ ·ï¼šè®©å°ç±»æ ·æœ¬æœ‰æ›´é«˜çš„è¢«é‡‡æ ·æ¦‚ç‡ ==========
    y_source_train = data_dict['y_source_train']
    class_counts = np.bincount(y_source_train)
    sampler = None

    if use_weighted_sampler:
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æƒé‡ï¼ˆé€†é¢‘ç‡ï¼‰
        class_weights = 1.0 / class_counts
        # å½’ä¸€åŒ–æƒé‡ï¼Œä½¿å¾—å¹³å‡æƒé‡ä¸º1
        class_weights = class_weights / class_weights.mean()

        # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ†é…æƒé‡
        sample_weights = class_weights[y_source_train]

        # åˆ›å»ºåŠ æƒé‡‡æ ·å™¨
        sampler = torch.utils.data.WeightedRandomSampler(
            weights=sample_weights,
            num_samples=len(sample_weights),
            replacement=True  # å…è®¸é‡å¤é‡‡æ ·
        )

        print(f"[ä¿¡æ¯] ä½¿ç”¨åŠ æƒé‡‡æ · - ç±»åˆ«æƒé‡: {class_weights}")
    else:
        print("[ä¿¡æ¯] æœªå¯ç”¨åŠ æƒé‡‡æ ·ï¼Œä½¿ç”¨éšæœºæ‰“ä¹±")
    print(f"[ä¿¡æ¯] ç±»åˆ«åˆ†å¸ƒ: {class_counts}")
    
    # ä½¿ç”¨sampleræ—¶ä¸èƒ½è®¾ç½®shuffle=True
    if sampler is not None:
        source_train_loader = DataLoader(
            source_train_dataset,
            batch_size=batch_size,
            sampler=sampler,  # ä½¿ç”¨åŠ æƒé‡‡æ ·å™¨
            drop_last=True,
            num_workers=0
        )
    else:
        source_train_loader = DataLoader(
            source_train_dataset,
            batch_size=batch_size,
            shuffle=True,
            drop_last=True,
            num_workers=0
        )
    source_val_loader = DataLoader(source_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    target_train_loader = DataLoader(target_train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)
    target_test_loader = DataLoader(target_test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    
    dann_loader = DANNDataLoader(source_train_loader, target_train_loader)
    
    return {
        'source_train': source_train_loader,
        'source_val': source_val_loader,
        'target_train': target_train_loader,
        'target_test': target_test_loader,
        'dann_train': dann_loader
    }


def train_one_epoch(model, dann_loader, optimizer, cls_criterion, domain_criterion,
                    device, epoch, total_epochs, config, phase_info=None) -> Dict:
    """
    è®­ç»ƒä¸€ä¸ªepoch - æ”¯æŒä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
    
    ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
    ==================== 
    é˜¶æ®µ1 (Epochs 1-50)ï¼šçº¯åˆ†ç±»è®­ç»ƒ
      - gamma_grl = 0
      - åªä¼˜åŒ–åˆ†ç±»æŸå¤±
      - ç›®æ ‡ï¼šç¡®ä¿æºåŸŸå‡†ç¡®ç‡ > 90%
    
    é˜¶æ®µ2 (Epochs 51-150)ï¼šåŸŸé€‚åº”è®­ç»ƒ
      - gamma_grl çº¿æ€§å¢é•¿åˆ° max_gamma
      - ç›‘æ§ç›®æ ‡åŸŸå‡†ç¡®ç‡
      - å¦‚æœæºåŸŸå‡†ç¡®ç‡ä¸‹é™ > 10%ï¼Œé™ä½ domain_loss_weight
    ====================
    """
    model.train()

    total_cls_loss = 0.0
    total_domain_loss = 0.0
    total_loss = 0.0
    num_batches = 0

    # ==================== ä¸¤é˜¶æ®µè®­ç»ƒå‚æ•° ====================
    da_config = config['training']['domain_adaptation']
    
    # é˜¶æ®µ1å‚æ•°
    phase1_epochs = da_config.get('phase1_epochs', 50)  # çº¯åˆ†ç±»é˜¶æ®µ
    
    # é˜¶æ®µ2å‚æ•°
    max_gamma_grl = da_config.get('gamma_grl', 2.0)  # æœ€ç»ˆçš„gammaå€¼
    domain_loss_weight = da_config.get('domain_loss_weight', 0.3)
    
    # ==================== ä¸¤é˜¶æ®µGRLè°ƒåº¦ ====================
    if epoch <= phase1_epochs:
        # é˜¶æ®µ1ï¼šçº¯åˆ†ç±»ï¼Œä¸è¿›è¡ŒåŸŸé€‚åº”
        grl_lambda = 0.0
        phase = 1
    else:
        # é˜¶æ®µ2ï¼šåŸŸé€‚åº”ï¼ŒGRLçº¿æ€§å¢é•¿
        phase = 2
        phase2_progress = (epoch - phase1_epochs) / (total_epochs - phase1_epochs)
        # çº¿æ€§å¢é•¿åˆ° max_gamma_grl
        grl_lambda = phase2_progress * max_gamma_grl
        
        # å¦‚æœæœ‰phase_infoï¼Œæ£€æŸ¥æºåŸŸå‡†ç¡®ç‡ä¿æŠ¤
        if phase_info is not None:
            source_acc_drop = phase_info.get('source_acc_drop', 0.0)
            if source_acc_drop > 0.10:  # æºåŸŸå‡†ç¡®ç‡ä¸‹é™è¶…è¿‡10%
                # é™ä½åŸŸæŸå¤±æƒé‡
                domain_loss_weight = domain_loss_weight * 0.5
    
    model.set_grl_alpha(grl_lambda)  # è®¾ç½®æ¢¯åº¦åè½¬å±‚çš„ alpha å€¼
    
    for source_batch, target_batch in dann_loader:
        x_source, y_source, _ = source_batch
        x_target, _, _ = target_batch
        
        x_source = x_source.to(device)
        y_source = y_source.to(device)
        x_target = x_target.to(device)
        
        optimizer.zero_grad()
        outputs = model(x_source, x_target)
        
        cls_loss = cls_criterion(outputs['class_logits'], y_source)
        
        # é˜¶æ®µ1ï¼šåªä¼˜åŒ–åˆ†ç±»æŸå¤±
        if phase == 1:
            loss = cls_loss
            domain_loss = torch.tensor(0.0).to(device)
        else:
            # é˜¶æ®µ2ï¼šåŠ å…¥åŸŸé€‚åº”æŸå¤±
            domain_source = torch.zeros(x_source.size(0), 1).to(device)
            domain_target = torch.ones(x_target.size(0), 1).to(device)
            domain_logits = torch.cat([outputs['domain_logits_source'], outputs['domain_logits_target']], dim=0)
            domain_labels = torch.cat([domain_source, domain_target], dim=0)
            domain_loss = domain_criterion(domain_logits, domain_labels)
            
            loss = cls_loss + domain_loss_weight * grl_lambda * domain_loss
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        total_cls_loss += cls_loss.item()
        total_domain_loss += domain_loss.item() if isinstance(domain_loss, torch.Tensor) else domain_loss
        total_loss += loss.item()
        num_batches += 1
    
    return {
        'cls_loss': total_cls_loss / num_batches,
        'domain_loss': total_domain_loss / num_batches,
        'total_loss': total_loss / num_batches,
        'grl_lambda': grl_lambda,
        'phase': phase
    }


def evaluate(model, dataloader, cls_criterion, device, prefix='val') -> Dict:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    
    all_preds, all_labels = [], []
    total_loss = 0.0
    num_batches = 0
    
    with torch.no_grad():
        for batch in dataloader:
            x, y, _ = batch
            x, y = x.to(device), y.to(device)
            
            outputs = model(x)
            loss = cls_criterion(outputs['class_logits'], y)
            total_loss += loss.item()
            
            preds = torch.argmax(outputs['class_logits'], dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(y.cpu().numpy())
            num_batches += 1
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    
    # è¯Šæ–­ï¼šæ£€æŸ¥é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ
    pred_dist = np.bincount(all_preds, minlength=7)
    label_dist = np.bincount(all_labels, minlength=7)
    unique_preds = len(np.unique(all_preds))
    if unique_preds <= 2:
        print(f"  âš ï¸ [{prefix}] ç±»åˆ«åå¡Œ! åªé¢„æµ‹{unique_preds}ç±»: pred={pred_dist}, label={label_dist}")
    
    metrics = calculate_metrics(all_labels, all_preds)
    metrics[f'{prefix}_loss'] = total_loss / num_batches
    
    return metrics


def extract_features(model, dataloader, device) -> tuple:
    """
    æå–æ¨¡å‹ç‰¹å¾ç”¨äº t-SNE å¯è§†åŒ–

    Returns:
        features: ç‰¹å¾å‘é‡ (N, feature_dim)
        labels: æ ‡ç­¾ (N,)
        domain_labels: åŸŸæ ‡ç­¾ (N,) - 0=source, 1=target
    """
    model.eval()
    all_features, all_labels, all_domains = [], [], []

    with torch.no_grad():
        for batch in dataloader:
            x, y, d = batch
            x = x.to(device)

            # ==================== ä¿®å¤ï¼šæ­£ç¡®æå–ç‰¹å¾ ====================
            # ç›´æ¥è°ƒç”¨ç‰¹å¾æå–å™¨ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ model(x) çš„è¾“å‡º
            # å› ä¸º model(x) åªè¿”å› class_logits å’Œ domain_logitsï¼Œä¸è¿”å›ç‰¹å¾
            try:
                # å°è¯•ç›´æ¥è°ƒç”¨ç‰¹å¾æå–å™¨
                features = model.feature_extractor(x)
            except AttributeError:
                # å¦‚æœæ²¡æœ‰ feature_extractor å±æ€§ï¼Œä½¿ç”¨å…¶ä»–æ–¹å¼
                outputs = model(x)
                if 'features_source' in outputs:
                    features = outputs['features_source']
                elif 'features' in outputs:
                    features = outputs['features']
                else:
                    # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨ class_logits ä½œä¸ºç‰¹å¾ï¼ˆè™½ç„¶ä¸ç†æƒ³ï¼‰
                    features = outputs['class_logits']

            all_features.append(features.cpu().numpy())
            all_labels.extend(y.numpy())
            all_domains.extend(d.numpy())

    return np.concatenate(all_features, axis=0), np.array(all_labels), np.array(all_domains)


def plot_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray, 
                          class_names: list, save_path: str, 
                          condition_name: str = "") -> None:
    """
    ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ ‡ç­¾
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        condition_name: å·¥å†µåç§°
    """
    try:
        from sklearn.metrics import confusion_matrix
        import matplotlib.pyplot as plt
        import matplotlib
        matplotlib.use('Agg')  # éäº¤äº’æ¨¡å¼
        
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        cm = confusion_matrix(y_true, y_pred)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        ax.figure.colorbar(im, ax=ax)
        
        # æ ‡ç­¾
        ax.set(xticks=np.arange(cm.shape[1]),
               yticks=np.arange(cm.shape[0]),
               xticklabels=class_names[:cm.shape[1]],
               yticklabels=class_names[:cm.shape[0]],
               title=f'æ··æ·†çŸ©é˜µ - {condition_name}',
               ylabel='çœŸå®æ ‡ç­¾',
               xlabel='é¢„æµ‹æ ‡ç­¾')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
        
        # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ˜¾ç¤ºæ•°å€¼
        thresh = cm.max() / 2.
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                ax.text(j, i, format(cm[i, j], 'd'),
                        ha="center", va="center",
                        color="white" if cm[i, j] > thresh else "black")
        
        fig.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"[ä¿¡æ¯] æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")
        
    except Exception as e:
        print(f"[è­¦å‘Š] æ··æ·†çŸ©é˜µç»˜åˆ¶å¤±è´¥: {e}")


def plot_tsne_visualization(source_features: np.ndarray, source_labels: np.ndarray,
                            target_features: np.ndarray, target_labels: np.ndarray,
                            class_names: list, save_path: str,
                            condition_name: str = "") -> None:
    """
    ç»˜åˆ¶ t-SNE ç‰¹å¾å¯è§†åŒ–å›¾
    
    Args:
        source_features: æºåŸŸç‰¹å¾
        source_labels: æºåŸŸæ ‡ç­¾
        target_features: ç›®æ ‡åŸŸç‰¹å¾
        target_labels: ç›®æ ‡åŸŸæ ‡ç­¾
        class_names: ç±»åˆ«åç§°
        save_path: ä¿å­˜è·¯å¾„
        condition_name: å·¥å†µåç§°
    """
    try:
        from sklearn.manifold import TSNE
        import matplotlib.pyplot as plt
        import matplotlib
        matplotlib.use('Agg')
        
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆå¹¶æºåŸŸå’Œç›®æ ‡åŸŸç‰¹å¾
        all_features = np.vstack([source_features, target_features])
        all_labels = np.concatenate([source_labels, target_labels])
        domain_labels = np.array([0] * len(source_labels) + [1] * len(target_labels))
        
        # å¦‚æœæ ·æœ¬å¤ªå¤šï¼Œéšæœºé‡‡æ ·
        max_samples = 2000
        if len(all_features) > max_samples:
            idx = np.random.choice(len(all_features), max_samples, replace=False)
            all_features = all_features[idx]
            all_labels = all_labels[idx]
            domain_labels = domain_labels[idx]
        
        print(f"[ä¿¡æ¯] æ­£åœ¨è®¡ç®— t-SNE (æ ·æœ¬æ•°: {len(all_features)})...")
        
        # å…¼å®¹æ–°ç‰ˆscikit-learn: n_iteræ”¹ä¸ºmax_iter
        tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)
        features_2d = tsne.fit_transform(all_features)
        
        # ç»˜åˆ¶ä¸¤ä¸ªå­å›¾
        fig, axes = plt.subplots(1, 2, figsize=(16, 7))
        
        # å­å›¾1: æŒ‰åŸŸåŒºåˆ†
        colors_domain = ['#1f77b4', '#ff7f0e']
        for d, (color, label) in enumerate(zip(colors_domain, ['HIL (Source)', 'Real (Target)'])):
            mask = domain_labels == d
            axes[0].scatter(features_2d[mask, 0], features_2d[mask, 1], 
                           c=color, label=label, alpha=0.6, s=15)
        axes[0].set_title(f't-SNE Domain Distribution - {condition_name}')
        axes[0].legend()
        axes[0].set_xlabel('t-SNE Dimension 1')
        axes[0].set_ylabel('t-SNE Dimension 2')
        
        # å­å›¾2: æŒ‰ç±»åˆ«åŒºåˆ†
        num_classes = len(class_names)
        cmap = plt.cm.get_cmap('tab10', num_classes)
        for c in range(num_classes):
            mask = all_labels == c
            if mask.sum() > 0:
                axes[1].scatter(features_2d[mask, 0], features_2d[mask, 1],
                               c=[cmap(c)], label=class_names[c], alpha=0.6, s=15)
        axes[1].set_title(f't-SNE Class Distribution - {condition_name}')
        axes[1].legend(loc='best', fontsize=8)
        axes[1].set_xlabel('t-SNE Dimension 1')
        axes[1].set_ylabel('t-SNE Dimension 2')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"[ä¿¡æ¯] t-SNE å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
        
    except Exception as e:
        print(f"[è­¦å‘Š] t-SNE å¯è§†åŒ–å¤±è´¥: {e}")


def final_evaluation_with_visualization(
    model, source_loader, target_loader, cls_criterion, device,
    condition: int, condition_name: str, results_dir: str, config: dict
) -> Dict:
    """
    æœ€ç»ˆè¯„ä¼°å¹¶ç”Ÿæˆå¯è§†åŒ–
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        source_loader: æºåŸŸéªŒè¯æ•°æ®åŠ è½½å™¨
        target_loader: ç›®æ ‡åŸŸæµ‹è¯•æ•°æ®åŠ è½½å™¨
        cls_criterion: åˆ†ç±»æŸå¤±å‡½æ•°
        device: è®¾å¤‡
        condition: å·¥å†µä»£ç 
        condition_name: å·¥å†µåç§°
        results_dir: ç»“æœä¿å­˜ç›®å½•
        config: é…ç½®
        
    Returns:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    print("\n>>> æœ€ç»ˆè¯„ä¼°ä¸å¯è§†åŒ–...")
    
    # ========== ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„ç±»åˆ«åç§°ï¼ˆä¸æ ‡ç­¾0-6ä¸¥æ ¼å¯¹åº”ï¼‰==========
    class_names = config['fault_types'].get('names', 
                  ['No_Fault', 'Motor', 'Accelerometer', 'Gyroscope', 
                   'Magnetometer', 'Barometer', 'GPS'])
    
    # è¯„ä¼°ç›®æ ‡åŸŸ
    model.eval()
    all_preds, all_labels = [], []
    
    with torch.no_grad():
        for batch in target_loader:
            x, y, _ = batch
            x = x.to(device)
            outputs = model(x)
            preds = torch.argmax(outputs['class_logits'], dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(y.numpy())
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    
    # ========== æ–°å¢ï¼šè¯„ä¼°æºåŸŸå¹¶ç”Ÿæˆé¢„æµ‹ ==========
    source_preds_cm, source_labels_cm = [], []
    with torch.no_grad():
        for batch in source_loader:
            x, y, _ = batch
            x = x.to(device)
            outputs = model(x)
            preds = torch.argmax(outputs['class_logits'], dim=1)
            source_preds_cm.extend(preds.cpu().numpy())
            source_labels_cm.extend(y.numpy())
    
    source_preds_cm = np.array(source_preds_cm)
    source_labels_cm = np.array(source_labels_cm)
    
    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    vis_dir = os.path.join(results_dir, 'visualizations')
    os.makedirs(vis_dir, exist_ok=True)
    
    # 1. ç”ŸæˆåŒæ··æ·†çŸ©é˜µï¼ˆæºåŸŸ + ç›®æ ‡åŸŸï¼‰
    cm_path = os.path.join(vis_dir, f'confusion_matrix_condition_{condition}.png')
    plot_dual_confusion_matrix(
        source_labels_cm, source_preds_cm,  # æºåŸŸ
        all_labels, all_preds,              # ç›®æ ‡åŸŸ
        class_names, cm_path, condition_name
    )
    
    # 2. t-SNE å¯è§†åŒ–
    try:
        source_features, source_labels, _ = extract_features(model, source_loader, device)
        target_features, target_labels, _ = extract_features(model, target_loader, device)
        
        tsne_path = os.path.join(vis_dir, f'tsne_condition_{condition}.png')
        plot_tsne_visualization(source_features, source_labels, 
                               target_features, target_labels,
                               class_names, tsne_path, condition_name)
    except Exception as e:
        print(f"[è­¦å‘Š] t-SNE ç‰¹å¾æå–å¤±è´¥: {e}")
    
    # ========== 3. åŸŸå¯¹é½åˆ†æ ==========
    # è¯„ä¼°æºåŸŸå‡†ç¡®ç‡
    source_preds, source_labels_eval = [], []
    with torch.no_grad():
        for batch in source_loader:
            x, y, _ = batch
            x = x.to(device)
            outputs = model(x)
            preds = torch.argmax(outputs['class_logits'], dim=1)
            source_preds.extend(preds.cpu().numpy())
            source_labels_eval.extend(y.numpy())
    
    source_metrics = calculate_metrics(np.array(source_labels_eval), np.array(source_preds))
    target_metrics_final = calculate_metrics(all_labels, all_preds)
    
    # è®¡ç®—åŸŸå·®è·
    domain_gap = source_metrics['accuracy'] - target_metrics_final['accuracy']
    
    # æ‰“å°åŸŸå¯¹é½åˆ†ææŠ¥å‘Š
    print("\n" + "=" * 60)
    print("åŸŸå¯¹é½åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    print(f"æºåŸŸ (HIL) å‡†ç¡®ç‡:   {source_metrics['accuracy']:.2%}")
    print(f"æºåŸŸ (HIL) F1åˆ†æ•°:   {source_metrics['f1_score']:.4f}")
    print(f"ç›®æ ‡åŸŸ (Real) å‡†ç¡®ç‡: {target_metrics_final['accuracy']:.2%}")
    print(f"ç›®æ ‡åŸŸ (Real) F1åˆ†æ•°: {target_metrics_final['f1_score']:.4f}")
    print("-" * 60)
    print(f"åŸŸå·®è· (Source - Target): {domain_gap:+.2%}")
    
    if abs(domain_gap) < 0.1:
        alignment_status = "âœ… ä¼˜ç§€ - åŸŸç‰¹å¾å¯¹é½è‰¯å¥½"
    elif abs(domain_gap) < 0.2:
        alignment_status = "âš ï¸ ä¸€èˆ¬ - å­˜åœ¨ä¸€å®šåŸŸåç§»"
    else:
        alignment_status = "âŒ è¾ƒå·® - åŸŸåç§»ä¸¥é‡ï¼Œéœ€ä¼˜åŒ–"
    print(f"å¯¹é½çŠ¶æ€: {alignment_status}")
    print("=" * 60)
    
    # è¿”å›å¢å¼ºçš„æŒ‡æ ‡
    final_metrics = target_metrics_final.copy()
    final_metrics['source_accuracy'] = source_metrics['accuracy']
    final_metrics['source_f1_score'] = source_metrics['f1_score']
    final_metrics['domain_gap'] = domain_gap
    
    return final_metrics


def train_single_condition(config_path: str, sc_config_path: str, condition: int, resume_path: Optional[str] = None) -> Dict:
    """
    å•å·¥å†µè¿ç§»è®­ç»ƒä¸»å‡½æ•°
    
    Args:
        config_path: ä¸»é…ç½®æ–‡ä»¶è·¯å¾„
        sc_config_path: å•å·¥å†µé…ç½®æ–‡ä»¶è·¯å¾„
        condition: é£è¡ŒçŠ¶æ€ä»£ç  (0-5)
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    with open(sc_config_path, 'r', encoding='utf-8') as f:
        sc_config = yaml.safe_load(f)
    
    condition_name = sc_config['conditions']['names'].get(condition, f"Condition_{condition}")
    
    print("=" * 70)
    print(f"UAV-DANN å•å·¥å†µè¿ç§»è®­ç»ƒ")
    print(f"é£è¡ŒçŠ¶æ€: {condition} ({condition_name})")
    print("=" * 70)
    
    set_seed(config['reproducibility']['seed'])
    device = get_device(config)
    
    # åŠ è½½æˆ–é¢„å¤„ç†æ•°æ®
    results_dir = sc_config['output']['results_dir']
    processed_path = os.path.join(results_dir, f'processed_data_condition_{condition}.pkl')
    
    if os.path.exists(processed_path):
        print("\n>>> åŠ è½½å·²å¤„ç†çš„æ•°æ®...")
        data_dict = load_single_condition_data(condition, results_dir)
    else:
        print("\n>>> å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        preprocessor = SingleConditionPreprocessor(
            config_path=config_path,
            sc_config_path=sc_config_path,
            condition=condition
        )
        data_dict = preprocessor.process(save_processed=True)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\n>>> åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    loaders = get_dataloaders_single_condition(data_dict, config, sc_config)
    
    from models.dann_deep import DANNDeep

    # åˆ›å»ºæ¨¡å‹
    print("\n>>> åˆ›å»ºæ¨¡å‹...")
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ·±åº¦é…ç½®
    mh = sc_config.get('training', {}).get('model_hyperparameters')
    
    if mh:
        print("[ä¿¡æ¯] æ£€æµ‹åˆ°æ·±åº¦æ¨¡å‹è¶…å‚æ•°ï¼Œä½¿ç”¨åŠ¨æ€ DANNDeep...")
        n_features = config['preprocessing']['n_features']
        seq_len = config['preprocessing']['window_size']
        num_classes = config['fault_types']['num_classes']
        
        # æå–å‚æ•°ï¼Œæä¾›é»˜è®¤å€¼
        cnn_conf = mh.get('cnn', {})
        lstm_conf = mh.get('lstm', {})
        clf_conf = mh.get('classifier', {})
        disc_conf = mh.get('discriminator', {})
        
        model = DANNDeep(
            n_features=n_features,
            seq_len=seq_len,
            num_classes=num_classes,
            cnn_layers=cnn_conf.get('num_layers', 2),
            cnn_channels=cnn_conf.get('channels', [64, 128]),
            lstm_hidden=lstm_conf.get('hidden_size', 128),
            lstm_layers=lstm_conf.get('num_layers', 2),
            lstm_dropout=lstm_conf.get('dropout', 0.5),
            lstm_bidirectional=lstm_conf.get('bidirectional', False),
            classifier_layers=clf_conf.get('num_layers', 2),
            classifier_hidden=clf_conf.get('hidden_dim', 64),
            classifier_dropout=clf_conf.get('dropout', 0.5),
            discriminator_layers=disc_conf.get('num_layers', 2),
            discriminator_hidden=disc_conf.get('hidden_dim', 64),
            # æ¨¡å‹æ¶æ„å¼€å…³
            use_layernorm=mh.get('use_layernorm', True),  # æ–°å¢
            use_batchnorm=mh.get('use_batchnorm', False),
            use_attention=mh.get('use_attention', True),
            use_residual=mh.get('use_residual', True)
        )
    else:
        print("[ä¿¡æ¯] ä½¿ç”¨æ ‡å‡†é…ç½®æ„å»ºæ¨¡å‹...")
        model = build_dann_from_config(config_path)
    
    model = model.to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"[ä¿¡æ¯] æ¨¡å‹å‚æ•°: {total_params:,}")
    
    # ä¼˜åŒ–å™¨ (ä¼˜å…ˆä½¿ç”¨å·¥å†µé…ç½®ï¼Œå¦åˆ™ä½¿ç”¨ä¸»é…ç½®)
    sc_training = sc_config.get('training', {})
    sc_optimizer = sc_training.get('optimizer', {})
    lr = float(sc_optimizer.get('learning_rate', config['training']['optimizer']['learning_rate']))
    weight_decay = float(sc_optimizer.get('weight_decay', config['training']['optimizer']['weight_decay']))
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ (ä¼˜å…ˆä½¿ç”¨å·¥å†µé…ç½®)
    sc_scheduler = sc_training.get('scheduler', config['training'].get('scheduler', {}))
    scheduler_name = sc_scheduler.get('name', 'step')
    
    if scheduler_name == 'warmup_cosine':
        warmup_epochs = sc_scheduler.get('warmup_epochs', 5)
        num_epochs = sc_training.get('num_epochs', config['training']['num_epochs'])
        
        def lr_lambda(epoch):
            if epoch < warmup_epochs:
                return float(epoch) / float(max(1, warmup_epochs))
            progress = float(epoch - warmup_epochs) / float(max(1, num_epochs - warmup_epochs))
            return 0.5 * (1.0 + np.cos(np.pi * progress))
        
        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    else:
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
    
    # ========== è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆå¯é€‰ç”¨äºæŸå¤±ï¼‰ ==========
    num_classes = config['fault_types']['num_classes']
    class_weights = compute_class_weights(data_dict['y_source_train'], num_classes, device)
    
    # ä»é…ç½®ä¸­è¯»å–æŸå¤±å‡½æ•°ç±»å‹
    loss_config = sc_training.get('loss', {})
    loss_type = loss_config.get('classification', 'focal_loss')
    use_class_weights = loss_config.get('use_class_weights')
    if use_class_weights is None:
        use_class_weights = loss_type != 'focal_loss'
    
    if loss_type == 'label_smoothing':
        epsilon = loss_config.get('label_smoothing_epsilon', 0.1)
        cls_criterion = LabelSmoothingCrossEntropy(
            num_classes=num_classes,
            epsilon=epsilon,
            weight=class_weights if use_class_weights else None
        )
        weight_note = " + ç±»åˆ«åŠ æƒ" if use_class_weights else ""
        print(f"[ä¿¡æ¯] ä½¿ç”¨ LabelSmoothingCE (epsilon={epsilon}){weight_note}")
    elif loss_type == 'cross_entropy':
        cls_criterion = nn.CrossEntropyLoss(weight=class_weights if use_class_weights else None)
        weight_note = " + ç±»åˆ«åŠ æƒ" if use_class_weights else ""
        print(f"[ä¿¡æ¯] ä½¿ç”¨ CrossEntropyLoss{weight_note}")
    else:
        focal_gamma = loss_config.get('focal_gamma', 2.0)
        cls_criterion = FocalLoss(gamma=focal_gamma, alpha=class_weights if use_class_weights else None)
        weight_note = " + ç±»åˆ«åŠ æƒ" if use_class_weights else ""
        print(f"[ä¿¡æ¯] ä½¿ç”¨ FocalLoss (gamma={focal_gamma}){weight_note}")
    
    domain_criterion = nn.BCEWithLogitsLoss()
    
    num_epochs = sc_training.get('num_epochs', config['training']['num_epochs'])
    early_stopping_patience = sc_training.get('early_stopping_patience', 15)
    
    checkpoint_dir = sc_config['output']['checkpoint_dir']
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # è®­ç»ƒ
    print("\n>>> å¼€å§‹è®­ç»ƒ...")
    print(f"ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥: é˜¶æ®µ1(çº¯åˆ†ç±», 1-50), é˜¶æ®µ2(åŸŸé€‚åº”, 51-{num_epochs})")
    best_target_acc = -float('inf')  # åˆå§‹åŒ–ä¸ºè´Ÿæ— ç©·ï¼Œç¡®ä¿èƒ½ä¿å­˜ç¬¬ä¸€ä¸ªæ»¡è¶³æ¡ä»¶çš„æ¨¡å‹
    best_epoch = 0
    patience_counter = 0
    history = []
    
    # ä¸¤é˜¶æ®µè®­ç»ƒï¼šè®°å½•é˜¶æ®µ1çš„æœ€ä½³æºåŸŸå‡†ç¡®ç‡
    phase1_best_source_acc = 0.0
    phase_info = None
    
    start_time = time.time()
    
    for epoch in range(1, num_epochs + 1):
        # è®¡ç®—phase_infoç”¨äºæºåŸŸå‡†ç¡®ç‡ä¿æŠ¤
        if epoch > 50 and phase1_best_source_acc > 0:
            current_source_acc = history[-1]['source_val_acc'] if history else 0.0
            source_acc_drop = phase1_best_source_acc - current_source_acc
            phase_info = {'source_acc_drop': source_acc_drop}
        
        # ğŸ”§ ä¿®å¤ï¼šä¼ å…¥sc_configå’Œphase_info
        train_metrics = train_one_epoch(model, loaders['dann_train'], optimizer, cls_criterion, domain_criterion, device, epoch, num_epochs, sc_config, phase_info)
        val_metrics = evaluate(model, loaders['source_val'], cls_criterion, device, 'val')
        target_metrics = evaluate(model, loaders['target_test'], cls_criterion, device, 'target')
        
        # é˜¶æ®µ1ï¼šè®°å½•æœ€ä½³æºåŸŸå‡†ç¡®ç‡
        if epoch <= 50:
            phase1_best_source_acc = max(phase1_best_source_acc, val_metrics['accuracy'])
        
        if scheduler is not None:
            scheduler.step()
        
        # ========== è°ƒè¯•ï¼šéªŒè¯æ•°æ®åŠ è½½æ˜¯å¦æ­£ç¡® ==========
        if epoch == 1:
            print("\n=== æ•°æ®éªŒè¯ (Epoch 1) ===")
            print(f"Source train size: {len(loaders['source_train'].dataset)}")
            print(f"Source val size: {len(loaders['source_val'].dataset)}")
            print(f"Target test size: {len(loaders['target_test'].dataset)}")
            
            # æ£€æŸ¥ä¸€ä¸ªbatchçš„æ•°æ®
            test_batch = next(iter(loaders['source_train']))
            test_x, test_y, test_d = test_batch
            print(f"\næ ·æœ¬ç»´åº¦æ£€æŸ¥:")
            print(f"  X shape: {test_x.shape}")  # åº”è¯¥æ˜¯ (batch, seq_len, n_features)
            print(f"  Y shape: {test_y.shape}, å€¼èŒƒå›´: [{test_y.min()}, {test_y.max()}]")
            print(f"  Yåˆ†å¸ƒ: {torch.bincount(test_y)}")
            
            # æ£€æŸ¥æ¨¡å‹è¾“å‡º
            model.eval()
            with torch.no_grad():
                test_out = model(test_x.to(device))
                test_logits = test_out['class_logits']
                test_preds = torch.argmax(test_logits, dim=1)
                print(f"\næ¨¡å‹è¾“å‡ºæ£€æŸ¥:")
                print(f"  Logits shape: {test_logits.shape}")
                print(f"  LogitsèŒƒå›´: [{test_logits.min():.3f}, {test_logits.max():.3f}]")
                print(f"  é¢„æµ‹åˆ†å¸ƒ: {torch.bincount(test_preds.cpu())}")
            model.train()
            print("=" * 60 + "\n")
        
        epoch_record = {
            'epoch': epoch,
            'train_loss': train_metrics['total_loss'],
            'source_val_acc': val_metrics['accuracy'],              # æºåŸŸéªŒè¯å‡†ç¡®ç‡
            'target_acc': target_metrics['accuracy'],
            'target_f1': target_metrics['f1_score'],
            'grl_lambda': train_metrics['grl_lambda'],
            # åŸŸå·®è·åˆ†æ (ä½¿ç”¨éªŒè¯é›†è€Œä¸æ˜¯è®­ç»ƒé›†)
            'domain_gap': val_metrics['accuracy'] - target_metrics['accuracy']
        }
        history.append(epoch_record)
        
        # å¢å¼ºæ‰“å°ï¼šæ˜¾ç¤ºéªŒè¯é›†å‡†ç¡®ç‡å’Œå½“å‰é˜¶æ®µ
        domain_gap = val_metrics['accuracy'] - target_metrics['accuracy']
        phase_str = f"P{train_metrics.get('phase', 1)}"
        print(f"[{phase_str}] Epoch {epoch:3d}/{num_epochs} | Loss: {train_metrics['total_loss']:.4f} | "
              f"Source: {val_metrics['accuracy']:.2%} | Target: {target_metrics['accuracy']:.2%} | "
              f"Gap: {domain_gap:+.2%} | F1: {target_metrics['f1_score']:.3f} | Î»: {train_metrics['grl_lambda']:.3f}")
        
        # ========== æ”¹è¿›3ï¼šæ¨¡å‹é€‰æ‹©é€»è¾‘ï¼ˆæºåŸŸçº¦æŸï¼‰ ==========
        # åªæœ‰å½“æºåŸŸå‡†ç¡®ç‡>50%æ—¶ï¼Œæ‰è€ƒè™‘ç›®æ ‡åŸŸè¡¨ç°
        source_acc = val_metrics['accuracy']
        target_acc = target_metrics['accuracy']
        
        # ç»¼åˆè¯„åˆ†ï¼šæºåŸŸ>50%æ‰æœ‰èµ„æ ¼ä½œä¸ºæœ€ä½³æ¨¡å‹
        if source_acc >= 0.5:
            # ç»¼åˆå¾—åˆ†: 70%ç›®æ ‡åŸŸ + 30%æºåŸŸ
            current_score = 0.7 * target_acc + 0.3 * source_acc
        else:
            # æºåŸŸå´©æºƒï¼šç»™è´Ÿåˆ†ï¼Œä¸è€ƒè™‘ä½œä¸ºæœ€ä½³æ¨¡å‹
            current_score = -1.0
        
        is_best = current_score > best_target_acc and source_acc >= 0.5
        if is_best:
            best_target_acc = current_score  # å®é™…å­˜å‚¨ç»¼åˆå¾—åˆ†
            best_epoch = epoch
            patience_counter = 0
            
            # ========== æ”¹è¿›4ï¼šå®Œå–„checkpointä¿å­˜ ==========
            save_path = os.path.join(checkpoint_dir, f'condition_{condition}_best.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
                'metrics': {
                    'source_acc': source_acc,
                    'target_acc': target_acc,
                    'target_f1': target_metrics['f1_score'],
                    'score': current_score
                },
                'condition': condition,
                'config': {
                    'lr': lr,
                    'weight_decay': weight_decay,
                    'loss_type': loss_type
                }
            }, save_path)
        else:
            patience_counter += 1
        
        if patience_counter >= early_stopping_patience:
            print(f"\n[ä¿¡æ¯] æ—©åœ! Best epoch: {best_epoch}, Best score: {best_target_acc:.4f}")
            break
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print(f"è®­ç»ƒå®Œæˆ! å·¥å†µ: {condition} ({condition_name})")
    print(f"æœ€ä½³Epoch: {best_epoch}, ç»¼åˆå¾—åˆ†: {best_target_acc:.4f} (0.7Ã—Target + 0.3Ã—Source)")
    print(f"è®­ç»ƒæ—¶é—´: {training_time/60:.2f} åˆ†é’Ÿ")
    print("=" * 70)
    
    # ========== ç”Ÿæˆå¯è§†åŒ– ==========
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œå¯è§†åŒ–
    best_model_path = os.path.join(checkpoint_dir, f'condition_{condition}_best.pth')
    if os.path.exists(best_model_path):
        try:
            checkpoint = torch.load(best_model_path, map_location=device, weights_only=False)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"[ä¿¡æ¯] å·²åŠ è½½æœ€ä½³æ¨¡å‹ (Epoch {checkpoint['epoch']})")
        except RuntimeError as e:
            print(f"[è­¦å‘Š] æ— æ³•åŠ è½½checkpointï¼ˆå¯èƒ½æ¨¡å‹æ¶æ„ä¸åŒ¹é…ï¼‰: {e}")
            print(f"[ä¿¡æ¯] ä½¿ç”¨å½“å‰è®­ç»ƒæœ€åçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°")
    else:
        if best_epoch == 0:
            print(f"[è­¦å‘Š] æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹æºåŸŸå‡†ç¡®ç‡æœªè¶…è¿‡50%ï¼Œæ— æœ€ä½³æ¨¡å‹ä¿å­˜")
            print(f"[ä¿¡æ¯] ä½¿ç”¨å½“å‰è®­ç»ƒæœ€åçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°")
    
    # æ‰§è¡Œæœ€ç»ˆè¯„ä¼°ä¸å¯è§†åŒ–
    final_metrics = final_evaluation_with_visualization(
        model=model,
        source_loader=loaders['source_val'],
        target_loader=loaders['target_test'],
        cls_criterion=cls_criterion,
        device=device,
        condition=condition,
        condition_name=condition_name,
        results_dir=results_dir,
        config=config
    )
    
    # ä¿å­˜ç»“æœ
    results = {
        'condition': condition,
        'condition_name': condition_name,
        'best_epoch': best_epoch,
        'best_target_acc': best_target_acc,
        'final_metrics': final_metrics,
        'training_time': training_time,
        'history': history
    }
    
    os.makedirs(results_dir, exist_ok=True)
    results_path = os.path.join(results_dir, f'training_results_condition_{condition}.json')
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"[ä¿¡æ¯] ç»“æœå·²ä¿å­˜è‡³: {results_path}")
    
    return results


def main():
    parser = argparse.ArgumentParser(description='UAV-DANN å•å·¥å†µè¿ç§»è®­ç»ƒ')
    
    parser.add_argument('--condition', type=int, default=0,
                        help='é£è¡ŒçŠ¶æ€ä»£ç  (0-5): 0=hover, 1=waypoint, 2=velocity, 3=circling, 4=acce, 5=dece')
    parser.add_argument('--config', type=str, default='./config/config.yaml')
    parser.add_argument('--sc_config', type=str, default=None,
                        help='å•å·¥å†µé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤è‡ªåŠ¨é€‰æ‹©: config/condition_{N}_{name}.yaml)')
    
    args = parser.parse_args()
    
    if args.condition not in range(6):
        print(f"[é”™è¯¯] é£è¡ŒçŠ¶æ€ä»£ç å¿…é¡»åœ¨0-5ä¹‹é—´")
        return
    
    # å·¥å†µåç§°æ˜ å°„
    condition_names = {0: 'hover', 1: 'waypoint', 2: 'velocity', 3: 'circling', 4: 'acce', 5: 'dece'}
    
    # è‡ªåŠ¨é€‰æ‹©å¯¹åº”å·¥å†µçš„é…ç½®æ–‡ä»¶
    if args.sc_config is None:
        cond_name = condition_names[args.condition]
        args.sc_config = f'./config/condition_{args.condition}_{cond_name}.yaml'
        print(f"[ä¿¡æ¯] ä½¿ç”¨å·¥å†µä¸“å±é…ç½®: {args.sc_config}")
    
    if not os.path.isabs(args.config):
        args.config = os.path.join(project_root, args.config)
    if not os.path.isabs(args.sc_config):
        args.sc_config = os.path.join(project_root, args.sc_config)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.sc_config):
        print(f"[é”™è¯¯] é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.sc_config}")
        return
    
    train_single_condition(args.config, args.sc_config, args.condition)


if __name__ == "__main__":
    main()

